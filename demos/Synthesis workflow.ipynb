{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from synthpop.recipes.starter2 import Starter\n",
    "from synthpop.census_helpers import Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Synthesis](img/hor_synthesis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What does it mean to synthesize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hh` and `p` synthesis datasets are built based on PUMA geographies. The dataset paths shows a `state`, followed by a `county` and an `acs` based year. In the following example, we see synthetic households and persons for the state of Alaska and all the counties that are inside the state. \n",
    "\n",
    "The main idea of this process is to use the public user microdata survey (PUMS) which is a sample of the acs answers provided at the maximum dissaggrgated geography as possible (the PUMA) and use it to match each record within a `block group`. Using PUMS and acs subject tables it is possible to build different household types and match persons to them, building a dataset that will show individual records following different characteristics (race of head, tenure, children, etc, etc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we have a list of synthesized counties for hh and p from the 02 (AK) state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_198.pdf           \u001b[0m\u001b[01;32mhh_02_188_2013.csv\u001b[0m*  \u001b[01;32mp_02_110_2013.csv\u001b[0m*\r\n",
      "02_261.pdf           \u001b[01;32mhh_02_195_2013.csv\u001b[0m*  \u001b[01;32mp_02_122_2013.csv\u001b[0m*\r\n",
      "02_290.pdf           \u001b[01;32mhh_02_198_2013.csv\u001b[0m*  \u001b[01;32mp_02_130_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_013_2013.csv\u001b[0m*  \u001b[01;32mhh_02_220_2013.csv\u001b[0m*  \u001b[01;32mp_02_150_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_016_2013.csv\u001b[0m*  \u001b[01;32mhh_02_230_2013.csv\u001b[0m*  \u001b[01;32mp_02_164_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_020_2013.csv\u001b[0m*  \u001b[01;32mhh_02_240_2013.csv\u001b[0m*  \u001b[01;32mp_02_170_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_050_2013.csv\u001b[0m*  \u001b[01;32mhh_02_261_2013.csv\u001b[0m*  \u001b[01;32mp_02_180_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_060_2013.csv\u001b[0m*  \u001b[01;32mhh_02_270_2013.csv\u001b[0m*  \u001b[01;32mp_02_185_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_068_2013.csv\u001b[0m*  \u001b[01;32mhh_02_275_2013.csv\u001b[0m*  \u001b[01;32mp_02_188_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_070_2013.csv\u001b[0m*  \u001b[01;32mhh_02_282_2013.csv\u001b[0m*  \u001b[01;32mp_02_195_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_090_2013.csv\u001b[0m*  \u001b[01;32mhh_02_290_2013.csv\u001b[0m*  \u001b[01;32mp_02_198_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_100_2013.csv\u001b[0m*  \u001b[01;32mp_02_013_2013.csv\u001b[0m*   \u001b[01;32mp_02_220_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_105_2013.csv\u001b[0m*  \u001b[01;32mp_02_016_2013.csv\u001b[0m*   \u001b[01;32mp_02_230_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_110_2013.csv\u001b[0m*  \u001b[01;32mp_02_020_2013.csv\u001b[0m*   \u001b[01;32mp_02_240_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_122_2013.csv\u001b[0m*  \u001b[01;32mp_02_050_2013.csv\u001b[0m*   \u001b[01;32mp_02_261_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_130_2013.csv\u001b[0m*  \u001b[01;32mp_02_060_2013.csv\u001b[0m*   \u001b[01;32mp_02_270_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_150_2013.csv\u001b[0m*  \u001b[01;32mp_02_068_2013.csv\u001b[0m*   \u001b[01;32mp_02_275_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_164_2013.csv\u001b[0m*  \u001b[01;32mp_02_070_2013.csv\u001b[0m*   \u001b[01;32mp_02_282_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_170_2013.csv\u001b[0m*  \u001b[01;32mp_02_090_2013.csv\u001b[0m*   \u001b[01;32mp_02_290_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_180_2013.csv\u001b[0m*  \u001b[01;32mp_02_100_2013.csv\u001b[0m*\r\n",
      "\u001b[01;32mhh_02_185_2013.csv\u001b[0m*  \u001b[01;32mp_02_105_2013.csv\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls 02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files looks like...\n",
    "hh = pd.read_csv('02/hh_02_290_2013.csv')\n",
    "p = pd.read_csv('02/p_02_290_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>serialno</th>\n",
       "      <th>RT</th>\n",
       "      <th>puma00</th>\n",
       "      <th>puma10</th>\n",
       "      <th>NP</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>BLD</th>\n",
       "      <th>TEN</th>\n",
       "      <th>VEH</th>\n",
       "      <th>...</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>hh_workers</th>\n",
       "      <th>seniors</th>\n",
       "      <th>sf_detached</th>\n",
       "      <th>tenure_mover</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010000910239</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>own not recent</td>\n",
       "      <td>3972</td>\n",
       "      <td>2</td>\n",
       "      <td>290</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010000165017</td>\n",
       "      <td>H</td>\n",
       "      <td>400</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>own not recent</td>\n",
       "      <td>3972</td>\n",
       "      <td>2</td>\n",
       "      <td>290</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012001118337</td>\n",
       "      <td>H</td>\n",
       "      <td>-9</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>two</td>\n",
       "      <td>one</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>own not recent</td>\n",
       "      <td>4164</td>\n",
       "      <td>2</td>\n",
       "      <td>290</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       serialno RT  puma00  puma10  NP  TYPE  BLD  TEN  VEH  ...  \\\n",
       "0           0  2010000910239  H     400      -9   1     1  2.0  1.0  0.0  ...   \n",
       "1           1  2010000165017  H     400      -9   1     1  2.0  1.0  0.0  ...   \n",
       "2           2  2012001118337  H      -9     400   2     1  2.0  2.0  0.0  ...   \n",
       "\n",
       "   hh_size  hh_workers  seniors  sf_detached    tenure_mover cat_id  state  \\\n",
       "0      one         one       no          yes  own not recent   3972      2   \n",
       "1      one         one       no          yes  own not recent   3972      2   \n",
       "2      two         one       no          yes  own not recent   4164      2   \n",
       "\n",
       "   county tract block group  \n",
       "0     290   100           1  \n",
       "1     290   100           1  \n",
       "2     290   100           1  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>serialno</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>puma00</th>\n",
       "      <th>puma10</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>JWTR</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SCH</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>...</th>\n",
       "      <th>ESR</th>\n",
       "      <th>HISP</th>\n",
       "      <th>PERNP</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_sex</th>\n",
       "      <th>race</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>hh_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012000016443</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>400</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>35 to 60</td>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>138262</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012000016443</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>400</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>35 to 60</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>138258</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012000016443</td>\n",
       "      <td>4</td>\n",
       "      <td>-9</td>\n",
       "      <td>400</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>19 and under</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>138242</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       serialno  SPORDER  puma00  puma10  AGEP  JWTR  RELP  SCH  \\\n",
       "0           0  2012000016443        1      -9     400    45   1.0     0  1.0   \n",
       "1           1  2012000016443        2      -9     400    45   NaN     1  1.0   \n",
       "2           2  2012000016443        4      -9     400    11   NaN     2  2.0   \n",
       "\n",
       "   SCHL  ...  ESR  HISP    PERNP  RAC1P  hispanic    person_age person_sex  \\\n",
       "0  19.0  ...  1.0     1  43200.0      4        no      35 to 60       male   \n",
       "1  21.0  ...  6.0     1      0.0      4        no      35 to 60     female   \n",
       "2   7.0  ...  NaN     1      NaN      4        no  19 and under     female   \n",
       "\n",
       "    race  cat_id hh_id  \n",
       "0  other  138262   112  \n",
       "1  other  138258   112  \n",
       "2  other  138242   112  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What does these tables represent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `marginals` and `joint distributions` for households and persons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Starter](img/Starter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. The `acs5` subject table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# census api key\n",
    "key = os.environ['CENSUS']\n",
    "\n",
    "# AK state\n",
    "state = '02'\n",
    "\n",
    "# 290 county (Yukon-Koyukuk)\n",
    "county = '290'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates starter object\n",
    "starter = Starter(key, state, county, acsyear=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we get from starter class?\n",
    "print([m for m in dir(starter) if not m.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains a bunch of methods and variables for a synthesized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...state and county pair\n",
    "starter.state, starter.county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `Census` object and his methods:  Tract and Block group acs subject tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![acs](img/subject_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown in the diagram, a first step that occurs when we create the `starter` object is that methods from `Census` constructor are also instantiated. This gives us back some relevant information. First, the `acs` 5 years [estimates tables](https://www.census.gov/data/developers/data-sets/acs-5year.html) by different geographies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter.h_acs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we instantiate the Starter class to create starter object we are also creating a census object\n",
    "c = Census(key, acsyear=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter.c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that has his own methods \n",
    "print([ m for m in dir(c) if not m.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Articulating `Census` and  `Starter` methods\n",
    "\n",
    "As we said, a first thing that takes place when creating `starter` is the generation of `block groups` and `tracts` tables for a group of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create and merge both tables with:\n",
    "c.block_group_and_tract_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above diagram it is shown that, inside the `Starter` class some methods from census object `c` are called. But something else to be pointed out here is that, this last one `c` is also calling other methods from `census` module. \n",
    "\n",
    "We are interested in the `acs5` method - which is inside the core.py module imported from `import census` module -. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported methods from census module\n",
    "print([ m for m in dir(c.c) if not m.startswith('__')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define some arbitrary household variables at block group and tract levels to consume `acs5` subject tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block group\n",
    "presence_of_children_columns = ['B11005_001E', 'B11005_002E', 'B11005_011E']\n",
    "block_group_size_attr=['B11005_001E'] # this is the total within the block group\n",
    "\n",
    "# census tract\n",
    "vehicle_columns = ['B08201_0%02dE' % i for i in range(1, 7)]\n",
    "tract_size_attr=['B08201_001E'] # this is the total within the tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = c.c.acs5.get(['NAME'] + presence_of_children_columns,\n",
    "                 geo={'for': \"tract:*\",\n",
    "                      'in': 'state: 02 county: 290'}, year=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = c.c.acs5.get(['NAME'] + presence_of_children_columns,\n",
    "                  geo={'for': \"block group:*\",\n",
    "                       'in': 'state: 02 county: 290'}, year=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both tables are merged at the highest disaggregation level (block group). To do it `scale and merge` Census method scales down from tract to block group level as it is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tract variables\n",
    "starter.h_acs[['NAME']+vehicle_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build the `acs` table for block group and tracts levels - this process is repeated for persons too, here we only demo households subject tables-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the None tract value correspond to all the tracts\n",
    "h_acs = c.block_group_and_tract_query(block_group_columns=presence_of_children_columns,\n",
    "                                       tract_columns=vehicle_columns, \n",
    "                                       state='02', county='290',\n",
    "                                       merge_columns=['tract', 'county', 'state'],\n",
    "                                       block_group_size_attr=\"B11005_001E\",\n",
    "                                       tract_size_attr=\"B08201_001E\",\n",
    "                                       tract=None, year=2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_acs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. `Categorize` subject tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we get the subject data for [households](https://github.com/UDST/synthpop/blob/0bc36f8fef036913b416e0d4eb8a3fda79fc70ad/synthpop/recipes/starter2.py#L52-L68) and [persons](https://github.com/UDST/synthpop/blob/0bc36f8fef036913b416e0d4eb8a3fda79fc70ad/synthpop/recipes/starter2.py#L131-L139) variables, the `acs` dataset is categorized by: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop import categorizer as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.categorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give us back a multindexed table with new names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_acs_cat = cat.categorize(h_acs, {(\"hh_children\", \"yes\"): \"B11005_002E\",\n",
    "                                   (\"hh_children\", \"no\"): \"B11005_011E\",\n",
    "                                   (\"hh_cars\", \"none\"): \"B08201_002E\",\n",
    "                                   (\"hh_cars\", \"one\"): \"B08201_003E\",\n",
    "                                   (\"hh_cars\", \"two or more\"):\n",
    "                                        \"B08201_004E + B08201_005E + B08201_006E\"},\n",
    "                           index_cols=['state', 'county', 'tract', 'block group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_acs_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... that can also be obtained by calling it from the `starter` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the entire table built in starter2\n",
    "starter.h_acs_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Geography relations for joint distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pums](img/download_pums.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the diagram, one important method from `Census` constructor is the:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.tract_to_puma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which returns the correspondant puma id for a given tract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tract in ['000100','000200','000300','000400']:\n",
    "    print('puma10 id for tract {} : {}'.format(tract, c.tract_to_puma(state, county, tract)[0]))\n",
    "    print('puma00 id for tract {} : {}'.format(tract, c.tract_to_puma(state, county, tract)[1]))\n",
    "    puma10, puma00 = c.tract_to_puma(state, county, tract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information will be mainly used to download `pums` from `aws` or `gcs` (depending on the acs requested year)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What we call slices?: the `PUMA` geographies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pums_rel](img/pums_tracts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUMS stands for Public Use Microdata Sample. These are individual records of survey responses with identifying\n",
    "information removed.These files do not include every record of every person who responded to the ACS. Only a select few that in turn, are representative of the population. \n",
    "\n",
    "The ACS samples 3.5 million addresses per year. The 1-year ACS PUMS file contains about 1% of all of the US households. The 5-year ACS PUMS file is the equivalent of five 1-year files, so it includes about 5% of all of the US households.\n",
    "\n",
    "By contrast, in aggregated tables or summary data, the individual records are categorized and weighted to create an estimate for the larger population. These estimates contains a Margin of Error (which is, to put it into simple words, the percentage of times we do not hit a target population type when we randomly select cases: e.g. 5%, etc. ).\n",
    "\n",
    "This means that, since `PUMS` microdata provides a sample of the ACS records it is necessary to create an estimate of how many persons/households the raw records represent.  This microdata has no geographies smaller than what we call `PUMAs`.\n",
    "\n",
    "PUMA is an area where the population of over 100,000 in – population of over 100,000, large enough to meet the disclosure avoidance requirements. It is identified by a five-digit code that is unique within each estate, and they nest within state or state equivalence.\n",
    "\n",
    "PUMAs are redefined after each Decennial Census. It is important to mention that PUMAs redefined after the 2010 Census were first used in 2012 ACS PUMS files. Multi-year files contain dual PUMAs vintages, for example, the 2010 to 2014 ACS PUMS files. PUMAs are built on Census Tracks and Counties, and can be combined to create rough approximations of towns, counties or cities for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUMS variables\n",
    "h_pums_cols = ('serialno', 'PUMA00','PUMA10', 'RT', 'NP', 'TYPE',\n",
    "               'R65', 'HINCP', 'VEH', 'MV', 'TEN', 'BLD', 'R18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pums = c.download_household_pums(state, puma10, puma00, usecols=h_pums_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `PUMS` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint distributions represents a total value for acs queried table. Since this last dataset contains aggregated data for tracts and block groups levels, and given that the PUMS are a representative sample of individual records - each serial number corresponds to a unique answer -, both tables will be used to build target values to be joined during the synthesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.joint_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build a dataframe with the target categories that we obtained querying the `acs subject table`. This, by calling the `category_combinations` method from the categorizer that will return all possible combinations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.category_combinations(h_acs_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, the `joint_distribution` method will return a sample and categories dataframes. This by following next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping functions to return values depending on slices dataframes\n",
    "def cars_cat(r):\n",
    "    if r.VEH == 0:\n",
    "        return \"none\"\n",
    "    elif r.VEH == 1:\n",
    "        return \"one\"\n",
    "    return \"two or more\"\n",
    "\n",
    "def children_cat(r):\n",
    "    if r.R18 == 1:\n",
    "        return \"yes\"\n",
    "    return \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pums, jd_households = cat.joint_distribution(h_pums,\n",
    "                                                cat.category_combinations(h_acs_cat.columns),\n",
    "                                                {\"hh_cars\": cars_cat,\n",
    "                                                 \"hh_children\": children_cat,\n",
    "                                                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1. Categories dataframe**\n",
    "\n",
    "This cointains the amount of cases (or frequencies) for each category combination within the PUMA geography. It is important to remark that this totals corresponds to all the tracts we passed to the `tract to puma` function. Given that PUMS returns individual answers for a bunch of variables, we can combine them based on acs subject table columns and get the totals of each combination for a group tracts. This will return a total value for a group of tracts (or PUMA). PUMAs are unique whitin a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2. Sample dataframe**\n",
    "\n",
    "This is the microdata puma df we downloaded for tracts 100 to 400, with a new `cat_id` combination column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Until this point, we...**:\n",
    "1. Queried the `acs5` subject table to get persons and households variables at block group and tracts levels\n",
    "2. Downloaded sample files (PUMS) containing the same variables with different standard names.\n",
    "3. Matched the tracts of the `county`, `state` pair with a puma id.\n",
    "4. Built combination of variables at puma level - or all the tracts that are cointained inside a puma id (e.g. households with no children and no cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Marginals, the block group level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginals are called from the `starter` object inside the `synthesize_all` function and returns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...for a group of available geographies inside a county/state pair\n",
    "list(starter.get_available_geography_ids())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = starter.get_available_geography_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for geog_id in indexes:\n",
    "    h_marg = starter.get_household_marginal_for_geography(geog_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***...the total value of a given variable for the block group geography levels:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the marginal table we stored for the last census tract (400)\n",
    "h_marg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in our acs5 categorized table, in the block group 1 of the 000400 tract (we only stored the last geography since we ran a for loop) there are 82 households with childs and 46 with one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can check these totals in our acs subject table...\n",
    "h_acs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the marginal values from the block group 1 of the 000400 census tract\n",
    "hh_marginals_tract_400_block_gp_1 = h_acs_cat.loc[tuple(list(starter.get_available_geography_ids())[7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_marginals_tract_400_block_gp_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sinthesize all: using `Starter` outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The iterative proportional fitting (IPF) procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![constraints](img/constraints.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop.ipf.ipf import calculate_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_constraint, _ = calculate_constraints(hh_marginals_tract_400_block_gp_1, jd_households.frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our contraints table\n",
    "h_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the number of iterations performed to achieve the constraint values\n",
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block group 1 of the census tract 400 we used to have 91 households with no cars, 46 with one car and 39 with two or more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_targets = hh_marginals_tract_400_block_gp_1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, our `joint_distributions` table gave us the total of that variable for the entire PUMA (in this case, `843 households with no children + 919 households with one children = 1762 households with no cars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_households[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_households['frequency'][:2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we will build new target values for each category total within the block group by multiplying the target and the proportion that this target represents in the entire PUMA - remember here, that our joint distribution table gets this total by combining different variables. In our case number of cars and children -\n",
    "\n",
    "`new_target = current_target * (proportion of the current target)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_category_idx_0 = 0\n",
    "sub_category_idx_1 = 2\n",
    "\n",
    "for target in range(len(bg_targets)):\n",
    "    total_cat = jd_households.frequency[sub_category_idx_0:sub_category_idx_1].sum()\n",
    "    sub_category_idx_0 += 2\n",
    "    sub_category_idx_1 += 2\n",
    "    print('Block group target value: %s'%str(bg_targets[target]))\n",
    "    print('Total value of the combined category is: %s'%str(total_cat))\n",
    "    print('Proportion of each category in the combined variables total: %s'%str(bg_targets[target] / total_cat))\n",
    "    print('New Block group target value: %s'%str(bg_targets[target]*(bg_targets[target] / total_cat)))\n",
    "    print('*********************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These new values that were built based on the proportion that each block group represents in the PUMA (for every category value) will be used to update our joint distributions table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_households.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...the totals we had for each `category combination`: 0; 1; 2; 3; 4 & 5 will be replaced using that proportion. This way we will define a new maximum value for every category within the block group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have a constraints table with categories from 0 to 2 (has no car and no children, has no car but children and has one car and no children) as we shown in the example above. We will need to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_constraints = jd_households[:3].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define new targets based on proportions\n",
    "new_targets = [4.69977298524404, 2.1075697211155378, 1.7706635622817228]\n",
    "\n",
    "next_constraints = current_constraints.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. update the constraints table\n",
    "fre = -1\n",
    "for t in new_targets:\n",
    "    fre +=1 \n",
    "    next_constraints[fre][1] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values will be updated inside an iterative process, where previous and next constraints will be evaluated under a maximum of `tolerance`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(current_constraints, next_constraints).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.abs(current_constraints, next_constraints).sum()>tolerance:\n",
    "    print('Recalculate constraints table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, the iteration will continue until reaching a group of new target values under the tolerance defined before. The man result of this process will be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... our marginals table with total values for the block group\n",
    "hh_marginals_tract_400_block_gp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated with new totals.\n",
    "h_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that will be used to update joint distributions frequencies\n",
    "jd_households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consuming the Census API we built a dataset with, for example, 91 aggregated cases for households with no car. Building the constraints table, we used PUMA geographies to determine the proportion that these 91 cases represents in a more dissaggregated level. With this estimation we determine that instead of 91, the block group 1 of the census tract 00400 from the Yukon-Koyukuk county in the Alaska state has 46.5 households with no car. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. The iterative proportional updating (IPU) procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ipu](img/ipf_ipu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop.ipu.ipu import household_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_constraint.index = jd_households.cat_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the `categories dataframe` - our joint distributions table- we mentioned in `2.3`, there is a `sample dataframe` which is the public user microdata sample - our pums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_sample_df = h_pums.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_sample_df.index.name = \"hh_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households_sample_df = households_sample_df.reset_index().set_index(\"serialno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_freq_table = cat._frequency_table(households_sample_df, jd_households.cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_freq_table = h_freq_table.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_freq_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Togheter, frequency tables and constraints will be used for weights matrix and fit quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights, fit_quality, iterations = household_weights(h_freq_table,\n",
    "                                                          None,\n",
    "                                                          h_constraint,\n",
    "                                                          None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop.ipu.ipu import _FrequencyAndConstraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_wrap = _FrequencyAndConstraints(h_freq_table, h_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper returns every `cat_id` column with non zero values:\n",
    "\n",
    "* `0` represents households with no car and no children \n",
    "* `1` represents households with no car and children \n",
    "* `2` represents households with one car and no children\n",
    "* `3` represents households with one car and children\n",
    "* `4` represents households with two or more cars and no children\n",
    "* `5` represents households with two or more cars and children\n",
    "\n",
    "The wrapper returns each variables combination (from 0 to 5) inside a tuple with:\n",
    "\n",
    "1) `cat_id` value\n",
    "\n",
    "2) a `weights matrix`\n",
    "\n",
    "3) the new target value (the `constraint` or maximum value that the combination can reach within the block group) we built in the `ipf`.\n",
    "\n",
    "4) the index of non zero column values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the information for all the combinations\n",
    "freq_wrap.iter_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here, we can see for category \"0\" that non zero values are...\n",
    "freq_wrap.get_column(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... in the index 0, 1, 2, 7, (...)\n",
    "h_freq_table[0][0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this wrapper, we build the fit quality od each `cat_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop.ipu.ipu import _average_fit_quality\n",
    "from synthpop.ipu.ipu import _fit_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights matrix\n",
    "weights = np.ones(len(h_freq_table), dtype='float')\n",
    "\n",
    "# column (this is the non-zero elements of the \"0\" cat_id column of the frequency table)\n",
    "cat_id_0_column = [e for e in freq_wrap.get_column(0)][1]\n",
    "\n",
    "# nz (this is the idx of the frequency table where non zero values are stored)\n",
    "cat_id_0_nz = [e for e in freq_wrap.get_column(0)][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the non zero values should have the same length when filtering the weights matrix\n",
    "len(cat_id_0_column) == len(weights[cat_id_0_nz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new target value for the block group\n",
    "constraint = [e for e in freq_wrap.get_column(0)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the \"fit quality\" value for cat_id \"0\"\n",
    "_fit_quality(cat_id_0_column, weights[cat_id_0_nz], constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is the result of multiplying the non-zero values by the weights matrix, which returns the total frequency of the category within the PUMA: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat_id_0_column * weights[cat_id_0_nz]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the total households with no car and no children(843)\n",
    "jd_households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of non zero values is weighted and then reduced by substracting the constraints..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat_id_0_column * weights[cat_id_0_nz]).sum() - constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and finally is expressed in terms of the constraint for that category - the 𝛿 parameter described in the IPU paper -. The absolute value of the relative difference between the weighted sum and the corresponding constraint may be used as a goodness of fit measure and is defined as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((cat_id_0_column * weights[cat_id_0_nz]).sum() - constraint) / constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically showing the proportion of the `cat_id` within the entire population of the PUMA. In the example of this first iteration, we have that for each household that `cat_id` == `0`, there are 17 households that could be out of that category (`cat_id` != `0`).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![constraints](img/ipu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will be repeated for all household types (or `cat_id`) and build a unique average value (which is the sum of each `_fit_quality` result divided by the number of `cat_id` columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_qual_0_to_5 = _average_fit_quality(freq_wrap, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_qual_0_to_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is explained on [A METHODOLOGY TO MATCH DISTRIBUTIONS OF BOTH HOUSEHOLD AND\n",
    "PERSON ATTRIBUTES IN THE GENERATION OF SYNTHETIC POPULATIONS ](http://www.scag.ca.gov/Documents/PopulationSynthesizerPaper_TRB.pdf), the IPU algorithm starts by assuming equal weights for all households in the sample. The algorithm then proceeds by adjusting weights for each household/person constraint in an iterative process until the constraints are matched as closely as possible for both household and person attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_change = np.inf\n",
    "convergence= 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_change > convergence:\n",
    "    print(\"Updating weights matrix until reaching a fit quality value under the convergence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights for the each household level constraint are adjusted by dividing the number of households in that category (i.e., the constraint value) by the weighted sum of the first household type column: \n",
    "\n",
    "The `_update_weights` creates the following adjustment `adj = constraint / float((column * weights).sum())` and use it to update weights (`weights * adj`). The weights for all households of each household type will be multiplied by this ratio to satisfy the constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sense, the `households_weights` function will finally return a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. An array of corrected weights that best matches each household type \n",
    "best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. And a fit quality based on the proportion of each hh type that reduces the fit changes under the convergence \n",
    "fit_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Built in ...\n",
    "iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Drawing synthetic population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![draw](img/draw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthpop import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_households = int(hh_marginals_tract_400_block_gp_1.groupby(level=0).sum().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = _FrequencyAndConstraints(h_freq_table, h_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = draw._draw_indexes(num_households, fac, best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_hh = h_pums.loc[indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_tbl = pd.DataFrame(\n",
    "        {'serialno': synth_hh.serialno.values,\n",
    "         'hh_id': synth_hh.index.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, synthetic persons dataset will be built based on `p_pums` and the `hh_id` of synthetic households. As follows: \n",
    "\n",
    "```\n",
    "synth_people = pd.merge(p_pums, mrg_tbl, left_on='serialno', right_on='serialno')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spop",
   "language": "python",
   "name": "spop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
